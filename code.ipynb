{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maimonahST/CCSIT_Infobot/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZFHknUfYQH"
      },
      "source": [
        "# CCSIT Infobot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use this webpage as a referense to complete the project https://platform.openai.com/docs/guides/fine-tuning"
      ],
      "metadata": {
        "id": "kVOX4GMN-t_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        " checks for format errors, provides basic statistics, and estimates token counts for fine-tuning costs."
      ],
      "metadata": {
        "id": "bBFtePNzl8xr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX23sDlXfYQM"
      },
      "source": [
        "### Upload a training file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tiktoken\n",
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "IRwsJdUmfxlW",
        "outputId": "97211a1e-c773-486b-bf2d-62e2c4ed68f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (0.5.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.7.22)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "4WvKlpuCS1P6",
        "outputId": "98eed646-6ede-4fd3-b9f7-36af3c77671f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path=\"/content/drive/MyDrive/Dataset/train_data.jsonl\"\n",
        "validation_data_path=\"/content/drive/MyDrive/Dataset/validation_data.jsonl\"\n",
        "test_data_path=\"/content/drive/MyDrive/Dataset/test_data.jsonl\"\n",
        "\n",
        "# Load the train data\n",
        "with open(train_data_path, 'r', encoding='utf-8') as f:\n",
        "    train_data = [json.loads(line) for line in f]\n",
        "\n",
        "# Load the validation data\n",
        "with open(validation_data_path, 'r', encoding='utf-8') as f:\n",
        "    validation_data = [json.loads(line) for line in f]\n",
        "\n",
        "# Load the test data\n",
        "with open(test_data_path, 'r', encoding='utf-8') as f:\n",
        "    test_data = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial data stats\n",
        "print(\"Train num examples:\", len(train_data))\n",
        "print(\"Validation num examples:\", len(validation_data))\n",
        "print(\"Test num examples:\", len(test_data))\n",
        "\n",
        "print(\"First example in train data:\")\n",
        "for message in train_data[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "print(\"First example in validation data:\")\n",
        "for message in validation_data[0][\"messages\"]:\n",
        "    print(message)\n",
        "\n",
        "print(\"First example in test data:\")\n",
        "for message in test_data[0][\"messages\"]:\n",
        "    print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05J-ROXZf-R7",
        "outputId": "e48d91bc-473d-442b-e26c-01804e079ba7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train num examples: 178\n",
            "Validation num examples: 23\n",
            "Test num examples: 44\n",
            "First example in train data:\n",
            "{'role': 'system', 'content': 'You are CCSIT infobot '}\n",
            "{'role': 'user', 'content': 'Tell me about Imam Abdulrahman Bin Faisal University.'}\n",
            "{'role': 'assistant', 'content': 'Imam Abdulrahman Bin Faisal University opened its doors to women and men in 1975 with two pioneering colleges - the College of Medicine and the College of Architecture.'}\n",
            "First example in validation data:\n",
            "{'role': 'system', 'content': 'You are CCSIT infobot '}\n",
            "{'role': 'user', 'content': 'Can you provide more details about the Master of Science (MS) degrees offered at CCSIT?'}\n",
            "{'role': 'assistant', 'content': 'Certainly! The Master of Science (MS) degrees at CCSIT include special majors such as Big Data and Cloud Computing, Information Security, and Software Engineering. These programs are designed to provide in-depth knowledge in these areas.'}\n",
            "First example in test data:\n",
            "{'role': 'system', 'content': 'You are CCSIT infobot '}\n",
            "{'role': 'user', 'content': 'What is the student population of the IAU university?'}\n",
            "{'role': 'assistant', 'content': 'The student population of the university is over 45,000.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format validation"
      ],
      "metadata": {
        "id": "TFORMsTRmWmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "def error_check(dataset):\n",
        "  for idx, ex in enumerate(dataset):\n",
        "      if not isinstance(ex, dict):\n",
        "          format_errors[\"data_type\"] += 1\n",
        "          continue\n",
        "\n",
        "      messages = ex.get(\"messages\", None)\n",
        "      if not messages:\n",
        "          format_errors[\"missing_messages_list\"] += 1\n",
        "          continue\n",
        "\n",
        "      for message_idx, message in enumerate(messages):\n",
        "          if \"role\" not in message or \"content\" not in message:\n",
        "              format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "          if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
        "              format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "          if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "              format_errors[\"unrecognized_role\"] += 1\n",
        "              print(f\"Unrecognized role in example {idx}, message {message_idx}\")\n",
        "\n",
        "          content = message.get(\"content\", None)\n",
        "          function_call = message.get(\"function_call\", None)\n",
        "\n",
        "          if (not content and not function_call) or not isinstance(content, str):\n",
        "              format_errors[\"missing_content\"] += 1\n",
        "              print(f\"missing content message in example {idx}\")\n",
        "\n",
        "      if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "          format_errors[\"example_missing_assistant_message\"] += 1\n",
        "          print(f\"Missing assistant message in example {idx}\")\n",
        "\n",
        "  if format_errors:\n",
        "      print(\"Found errors:\")\n",
        "      for k, v in format_errors.items():\n",
        "          print(f\"{k}: {v}\")\n",
        "  else:\n",
        "      print(\"No errors found\")\n"
      ],
      "metadata": {
        "id": "lMZfKFA2hThs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check errors in train data\n",
        "error_check(train_data)"
      ],
      "metadata": {
        "id": "xGwOAKfKVSJs",
        "outputId": "3f0a1e95-0b18-4924-8fcb-e54fac84e551",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check errors in validation data\n",
        "error_check(validation_data)"
      ],
      "metadata": {
        "id": "GPe1_i83VepZ",
        "outputId": "d62f390a-5b29-4e29-f47b-af14879ade49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check errors in test data\n",
        "error_check(test_data)"
      ],
      "metadata": {
        "id": "eqt4FzF4VhXc",
        "outputId": "e99ac152-f711-4bf8-f7b3-f87bb81ac93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Counting Utilities"
      ],
      "metadata": {
        "id": "kSW0khbgpy2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ],
      "metadata": {
        "id": "ceeeHBFvp0oe"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in train_data:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gJKxbep8wd",
        "outputId": "0874e491-006b-4871-f735-f13e8dc5ab48"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 39, 432\n",
            "mean / median: 87.64044943820225, 80.5\n",
            "p5 / p95: 63.0, 113.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 8, 389\n",
            "mean / median: 52.92134831460674, 48.0\n",
            "p5 / p95: 28.0, 75.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cost Estimation"
      ],
      "metadata": {
        "id": "JZC8v2J6qQs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(train_data)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAxFAZxCqWdP",
        "outputId": "21de7a87-e126-453d-a990-e187b4103f03"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~15600 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~46800 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload training, validation, and testing file\n"
      ],
      "metadata": {
        "id": "1uBXMEuori5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFz05RIT3ejX",
        "outputId": "d595ba79-f972-4d3f-c95f-19daa3580eaf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.1.1)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.1)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "client=OpenAI(api_key = \"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\")"
      ],
      "metadata": {
        "id": "4r_cawJU3aRm"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "uJtWEYkzfYQP",
        "outputId": "538fcc4b-5d05-4a06-84ad-08fc2f1b4c17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-f2dbaa5bcd57>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_upload_response = openai.File.create(\n\u001b[0m\u001b[1;32m      2\u001b[0m   \u001b[0mfile\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/Dataset/train_data.jsonl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mpurpose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'fine-tune'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m )\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: module 'openai' has no attribute 'File'"
          ]
        }
      ],
      "source": [
        "train_upload_response = openai.File.create(\n",
        "  file=open(\"/content/drive/MyDrive/Dataset/train_data.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "\n",
        "validation_upload_response = openai.File.create(\n",
        "  file=open(\"/content/drive/MyDrive/Dataset/validation_data.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")\n",
        "\n",
        "test_upload_response = openai.File.create(\n",
        "  file=open(\"/content/drive/MyDrive/Dataset/test_data.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://api.openai.com/v1/files \\  -H \"Authorization: Bearer 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\""
      ],
      "metadata": {
        "id": "QPgy_7cPczpX",
        "outputId": "275ee648-9e47-488a-f3e4-0dd00c6e2b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"object\": \"list\",\n",
            "  \"has_more\": false,\n",
            "  \"data\": [\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-DT9nu6KVchTz67lWD8rh9iDo\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 23407,\n",
            "      \"created_at\": 1698860303,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-N50kRtX450lD053IMAiUsC0k\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 86611,\n",
            "      \"created_at\": 1698860302,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    },\n",
            "    {\n",
            "      \"object\": \"file\",\n",
            "      \"id\": \"file-KwUnDD4gOnTzxlAfmXn13tpK\",\n",
            "      \"purpose\": \"fine-tune\",\n",
            "      \"filename\": \"file\",\n",
            "      \"bytes\": 11148,\n",
            "      \"created_at\": 1698860302,\n",
            "      \"status\": \"processed\",\n",
            "      \"status_details\": null\n",
            "    }\n",
            "  ]\n",
            "}\n",
            "curl: (3) URL using bad/illegal format or missing URL\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train_file_id = train_upload_response.id\n",
        "# validation_file_id = validation_upload_response.id\n",
        "# test_file_id = test_upload_response.id\n",
        "\n",
        "train_file_id = \"file-N50kRtX450lD053IMAiUsC0k\"\n",
        "validation_file_id = \"file-KwUnDD4gOnTzxlAfmXn13tpK\"\n",
        "test_file_id = \"file-DT9nu6KVchTz67lWD8rh9iDo\"\n",
        "\n",
        "\n",
        "print(train_file_id)\n",
        "print(validation_file_id)\n",
        "print(test_file_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yo_ahieyufV",
        "outputId": "9d7188dd-a684-4b75-b49b-f93fe1ca76b8"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "file-N50kRtX450lD053IMAiUsC0k\n",
            "file-KwUnDD4gOnTzxlAfmXn13tpK\n",
            "file-DT9nu6KVchTz67lWD8rh9iDo\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "file_id = file-oslcAaIGlmzqflruENJaJDbl"
      ],
      "metadata": {
        "id": "uRSQgEfF3rv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a fine-tuned model"
      ],
      "metadata": {
        "id": "mvGqJ7hxrsUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = client.fine_tuning.jobs.create(training_file=train_file_id, model=\"gpt-3.5-turbo\", validation_file=validation_file_id)\n",
        "\n",
        "job_id = job.id"
      ],
      "metadata": {
        "id": "4U61p3BUruNz",
        "outputId": "9bb2f806-687f-4d6c-bfb3-eaecb034c87f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "BadRequestError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-aa2887bc02ba>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfine_tuning\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_file_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"gpt-3.5-turbo\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_file_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mjob_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/resources/fine_tuning/jobs.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, model, training_file, hyperparameters, suffix, validation_file, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    102\u001b[0m           \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOverride\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlevel\u001b[0m \u001b[0mdefault\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mthis\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseconds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \"\"\"\n\u001b[0;32m--> 104\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    105\u001b[0m             \u001b[0;34m\"/fine_tuning/jobs\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m             body=maybe_transform(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1054\u001b[0m         )\n\u001b[0;32m-> 1055\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1056\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1057\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    832\u001b[0m         \u001b[0mstream_cls\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_StreamT\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    833\u001b[0m     ) -> ResponseT | _StreamT:\n\u001b[0;32m--> 834\u001b[0;31m         return self._request(\n\u001b[0m\u001b[1;32m    835\u001b[0m             \u001b[0mcast_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m             \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    875\u001b[0m             \u001b[0;31m# to completion before attempting to access the response text.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m             \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 877\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    878\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mhttpx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTimeoutException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mretries\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': 'Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview', 'type': 'invalid_request_error', 'param': None, 'code': 'exceeded_quota'}}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!curl https://api.openai.com/v1/fine_tuning/jobs \\\n",
        "  -H \"Content-Type: application/json\" \\\n",
        "  -H \"Authorization: Bearer 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\" \\\n",
        "  -d '{ \"training_file\": \"file-N50kRtX450lD053IMAiUsC0k\", \"validation_file\": \"file-KwUnDD4gOnTzxlAfmXn13tpK\", \"model\": \"gpt-3.5-turbo\" }'"
      ],
      "metadata": {
        "id": "ALrsmNAWPirP",
        "outputId": "dd7b39a9-a49b-42ae-85bf-1c68c66f3c2f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"error\": {\n",
            "    \"message\": \"Fine-tuning jobs cannot be created on an Explore plan. You can upgrade to a paid plan on your billing page: https://platform.openai.com/account/billing/overview\",\n",
            "    \"type\": \"invalid_request_error\",\n",
            "    \"param\": null,\n",
            "    \"code\": \"exceeded_quota\"\n",
            "  }\n",
            "}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "id": "nh-tIRoCHU7s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "job_id = ftjob-lrbo5SsbJkPOTZBkCbOkqkbW"
      ],
      "metadata": {
        "id": "er39VnpT30mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List 10 fine-tuning jobs\n",
        "openai.FineTuningJob.list(limit=10)\n"
      ],
      "metadata": {
        "id": "UxOtZK1H2n1V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = \"ftjob-lrbo5SsbJkPOTZBkCbOkqkbW\""
      ],
      "metadata": {
        "id": "64SpI-oT3_E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "openai.FineTuningJob.retrieve(job_id)"
      ],
      "metadata": {
        "id": "CYC_pfj4Hh6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a fine-tuned model"
      ],
      "metadata": {
        "id": "kTyE9pEp1JFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8EL0BRBX\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are CCSIT infobot which provide facts about ccsit\"},\n",
        "    {\"role\": \"user\", \"content\": \"tell me about Dr. Yasser Abdullah Alahmadi?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "Zy_y9u0m1LCl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8EL0BRBX\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are CCSIT infobot which provide facts about ccsit \"},\n",
        "    {\"role\": \"user\", \"content\": \"what aramco chair offer? \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "v3PUd5hL43Ky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing your fine-tuned model"
      ],
      "metadata": {
        "id": "YcCJBuxE5NHR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggsUId748DN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
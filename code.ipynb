{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maimonahST/CCSIT_Infobot/blob/main/code.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STZFHknUfYQH"
      },
      "source": [
        "# CCSIT Infobot"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "use this webpage as a referense to complete the project https://platform.openai.com/docs/guides/fine-tuning"
      ],
      "metadata": {
        "id": "kVOX4GMN-t_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data preparation and analysis for chat model fine-tuning\n",
        " checks for format errors, provides basic statistics, and estimates token counts for fine-tuning costs."
      ],
      "metadata": {
        "id": "bBFtePNzl8xr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gX23sDlXfYQM"
      },
      "source": [
        "### Upload a training file"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import tiktoken # for token counting\n",
        "import numpy as np\n",
        "from collections import defaultdict"
      ],
      "metadata": {
        "id": "IRwsJdUmfxlW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = \"dataset.jsonl\"\n",
        "\n",
        "# Load the dataset\n",
        "with open(data_path, 'r', encoding='utf-8') as f:\n",
        "    dataset = [json.loads(line) for line in f]\n",
        "\n",
        "# Initial dataset stats\n",
        "print(\"Num examples:\", len(dataset))\n",
        "print(\"First example:\")\n",
        "for message in dataset[0][\"messages\"]:\n",
        "    print(message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05J-ROXZf-R7",
        "outputId": "6a4c971f-53dc-4b56-bc9e-3352ce5800b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples: 245\n",
            "First example:\n",
            "{'role': 'system', 'content': 'You are CCSIT infobot '}\n",
            "{'role': 'user', 'content': 'Tell me about Imam Abdulrahman Bin Faisal University.'}\n",
            "{'role': 'assistant', 'content': 'Imam Abdulrahman Bin Faisal University opened its doors to women and men in 1975 with two pioneering colleges - the College of Medicine and the College of Architecture.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format validation"
      ],
      "metadata": {
        "id": "TFORMsTRmWmo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Format error checks\n",
        "format_errors = defaultdict(int)\n",
        "\n",
        "for idx, ex in enumerate(dataset):\n",
        "    if not isinstance(ex, dict):\n",
        "        format_errors[\"data_type\"] += 1\n",
        "        continue\n",
        "\n",
        "    messages = ex.get(\"messages\", None)\n",
        "    if not messages:\n",
        "        format_errors[\"missing_messages_list\"] += 1\n",
        "        continue\n",
        "\n",
        "    for message_idx, message in enumerate(messages):\n",
        "        if \"role\" not in message or \"content\" not in message:\n",
        "            format_errors[\"message_missing_key\"] += 1\n",
        "\n",
        "        if any(k not in (\"role\", \"content\", \"name\", \"function_call\") for k in message):\n",
        "            format_errors[\"message_unrecognized_key\"] += 1\n",
        "\n",
        "        if message.get(\"role\", None) not in (\"system\", \"user\", \"assistant\", \"function\"):\n",
        "            format_errors[\"unrecognized_role\"] += 1\n",
        "            print(f\"Unrecognized role in example {idx}, message {message_idx}\")\n",
        "\n",
        "        content = message.get(\"content\", None)\n",
        "        function_call = message.get(\"function_call\", None)\n",
        "\n",
        "        if (not content and not function_call) or not isinstance(content, str):\n",
        "            format_errors[\"missing_content\"] += 1\n",
        "            print(f\"missing content message in example {idx}\")\n",
        "\n",
        "    if not any(message.get(\"role\", None) == \"assistant\" for message in messages):\n",
        "        format_errors[\"example_missing_assistant_message\"] += 1\n",
        "        print(f\"Missing assistant message in example {idx}\")\n",
        "\n",
        "if format_errors:\n",
        "    print(\"Found errors:\")\n",
        "    for k, v in format_errors.items():\n",
        "        print(f\"{k}: {v}\")\n",
        "else:\n",
        "    print(\"No errors found\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMZfKFA2hThs",
        "outputId": "7c4dacfd-9c9e-49fa-917c-d65f592b1b76"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No errors found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Token Counting Utilities"
      ],
      "metadata": {
        "id": "kSW0khbgpy2G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoding = tiktoken.get_encoding(\"cl100k_base\")\n",
        "\n",
        "def num_tokens_from_messages(messages, tokens_per_message=3, tokens_per_name=1):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        num_tokens += tokens_per_message\n",
        "        for key, value in message.items():\n",
        "            num_tokens += len(encoding.encode(value))\n",
        "            if key == \"name\":\n",
        "                num_tokens += tokens_per_name\n",
        "    num_tokens += 3\n",
        "    return num_tokens\n",
        "\n",
        "def num_assistant_tokens_from_messages(messages):\n",
        "    num_tokens = 0\n",
        "    for message in messages:\n",
        "        if message[\"role\"] == \"assistant\":\n",
        "            num_tokens += len(encoding.encode(message[\"content\"]))\n",
        "    return num_tokens\n",
        "\n",
        "def print_distribution(values, name):\n",
        "    print(f\"\\n#### Distribution of {name}:\")\n",
        "    print(f\"min / max: {min(values)}, {max(values)}\")\n",
        "    print(f\"mean / median: {np.mean(values)}, {np.median(values)}\")\n",
        "    print(f\"p5 / p95: {np.quantile(values, 0.1)}, {np.quantile(values, 0.9)}\")"
      ],
      "metadata": {
        "id": "ceeeHBFvp0oe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Warnings and tokens counts\n",
        "n_missing_system = 0\n",
        "n_missing_user = 0\n",
        "n_messages = []\n",
        "convo_lens = []\n",
        "assistant_message_lens = []\n",
        "\n",
        "for ex in dataset:\n",
        "    messages = ex[\"messages\"]\n",
        "    if not any(message[\"role\"] == \"system\" for message in messages):\n",
        "        n_missing_system += 1\n",
        "    if not any(message[\"role\"] == \"user\" for message in messages):\n",
        "        n_missing_user += 1\n",
        "    n_messages.append(len(messages))\n",
        "    convo_lens.append(num_tokens_from_messages(messages))\n",
        "    assistant_message_lens.append(num_assistant_tokens_from_messages(messages))\n",
        "\n",
        "print(\"Num examples missing system message:\", n_missing_system)\n",
        "print(\"Num examples missing user message:\", n_missing_user)\n",
        "print_distribution(n_messages, \"num_messages_per_example\")\n",
        "print_distribution(convo_lens, \"num_total_tokens_per_example\")\n",
        "print_distribution(assistant_message_lens, \"num_assistant_tokens_per_example\")\n",
        "n_too_long = sum(l > 4096 for l in convo_lens)\n",
        "print(f\"\\n{n_too_long} examples may be over the 4096 token limit, they will be truncated during fine-tuning\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7gJKxbep8wd",
        "outputId": "0018d3bb-cb18-4ed4-86e8-2f75ce8138c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num examples missing system message: 0\n",
            "Num examples missing user message: 0\n",
            "\n",
            "#### Distribution of num_messages_per_example:\n",
            "min / max: 3, 3\n",
            "mean / median: 3.0, 3.0\n",
            "p5 / p95: 3.0, 3.0\n",
            "\n",
            "#### Distribution of num_total_tokens_per_example:\n",
            "min / max: 39, 432\n",
            "mean / median: 89.4530612244898, 83.0\n",
            "p5 / p95: 63.0, 114.0\n",
            "\n",
            "#### Distribution of num_assistant_tokens_per_example:\n",
            "min / max: 8, 389\n",
            "mean / median: 54.608163265306125, 49.0\n",
            "p5 / p95: 28.0, 76.0\n",
            "\n",
            "0 examples may be over the 4096 token limit, they will be truncated during fine-tuning\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cost Estimation"
      ],
      "metadata": {
        "id": "JZC8v2J6qQs9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Pricing and default n_epochs estimate\n",
        "MAX_TOKENS_PER_EXAMPLE = 4096\n",
        "\n",
        "TARGET_EPOCHS = 3\n",
        "MIN_TARGET_EXAMPLES = 100\n",
        "MAX_TARGET_EXAMPLES = 25000\n",
        "MIN_DEFAULT_EPOCHS = 1\n",
        "MAX_DEFAULT_EPOCHS = 25\n",
        "\n",
        "n_epochs = TARGET_EPOCHS\n",
        "n_train_examples = len(dataset)\n",
        "if n_train_examples * TARGET_EPOCHS < MIN_TARGET_EXAMPLES:\n",
        "    n_epochs = min(MAX_DEFAULT_EPOCHS, MIN_TARGET_EXAMPLES // n_train_examples)\n",
        "elif n_train_examples * TARGET_EPOCHS > MAX_TARGET_EXAMPLES:\n",
        "    n_epochs = max(MIN_DEFAULT_EPOCHS, MAX_TARGET_EXAMPLES // n_train_examples)\n",
        "\n",
        "n_billing_tokens_in_dataset = sum(min(MAX_TOKENS_PER_EXAMPLE, length) for length in convo_lens)\n",
        "print(f\"Dataset has ~{n_billing_tokens_in_dataset} tokens that will be charged for during training\")\n",
        "print(f\"By default, you'll train for {n_epochs} epochs on this dataset\")\n",
        "print(f\"By default, you'll be charged for ~{n_epochs * n_billing_tokens_in_dataset} tokens\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KAxFAZxCqWdP",
        "outputId": "3b8e2820-0a33-457b-c0e9-d0228a3c0d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has ~21916 tokens that will be charged for during training\n",
            "By default, you'll train for 3 epochs on this dataset\n",
            "By default, you'll be charged for ~65748 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload a training file\n"
      ],
      "metadata": {
        "id": "1uBXMEuori5h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NFz05RIT3ejX",
        "outputId": "4b3d8e44-8907-4adb-ee78-47765f08dd05"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/77.0 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai) (2.31.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai) (3.8.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.3.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai) (2023.7.22)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai) (1.3.1)\n",
            "Installing collected packages: openai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-0.28.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "openai.api_key = \"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\""
      ],
      "metadata": {
        "id": "4r_cawJU3aRm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uJtWEYkzfYQP"
      },
      "outputs": [],
      "source": [
        "\n",
        "upload_response = openai.File.create(\n",
        "  file=open(\"dataset.jsonl\", \"rb\"),\n",
        "  purpose='fine-tune'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "file_id = upload_response.id\n",
        "file_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "4yo_ahieyufV",
        "outputId": "ab6988aa-5614-477c-e8ae-fb18214ee058"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'file-oslcAaIGlmzqflruENJaJDbl'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "file_id = file-oslcAaIGlmzqflruENJaJDbl"
      ],
      "metadata": {
        "id": "uRSQgEfF3rv8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a fine-tuned model"
      ],
      "metadata": {
        "id": "mvGqJ7hxrsUS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "job = openai.FineTuningJob.create(training_file=file_id, model=\"gpt-3.5-turbo\")\n",
        "\n",
        "job_id = job.id"
      ],
      "metadata": {
        "id": "4U61p3BUruNz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "job_id"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "nh-tIRoCHU7s",
        "outputId": "52210723-9c60-4355-c199-25a8926a6fd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ftjob-lrbo5SsbJkPOTZBkCbOkqkbW'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "job_id = ftjob-lrbo5SsbJkPOTZBkCbOkqkbW"
      ],
      "metadata": {
        "id": "er39VnpT30mG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# List 10 fine-tuning jobs\n",
        "openai.FineTuningJob.list(limit=10)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxOtZK1H2n1V",
        "outputId": "24b28a2f-7177-483e-837d-e4b9e1be64da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<OpenAIObject list at 0x7fa7e4336570> JSON: {\n",
              "  \"object\": \"list\",\n",
              "  \"data\": [\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-lrbo5SsbJkPOTZBkCbOkqkbW\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1698426471,\n",
              "      \"finished_at\": null,\n",
              "      \"fine_tuned_model\": null,\n",
              "      \"organization_id\": \"org-HSbO0AHQitnU5PUzeD33jzWV\",\n",
              "      \"result_files\": [],\n",
              "      \"status\": \"running\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-oslcAaIGlmzqflruENJaJDbl\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": null,\n",
              "      \"error\": null\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-yPDyIjz59ojF55CnXEg5lgyD\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1698426461,\n",
              "      \"finished_at\": null,\n",
              "      \"fine_tuned_model\": null,\n",
              "      \"organization_id\": \"org-HSbO0AHQitnU5PUzeD33jzWV\",\n",
              "      \"result_files\": [],\n",
              "      \"status\": \"running\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-oslcAaIGlmzqflruENJaJDbl\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": null,\n",
              "      \"error\": null\n",
              "    },\n",
              "    {\n",
              "      \"object\": \"fine_tuning.job\",\n",
              "      \"id\": \"ftjob-Cu7prgIKh9kku1QW44rtbXD7\",\n",
              "      \"model\": \"gpt-3.5-turbo-0613\",\n",
              "      \"created_at\": 1698426453,\n",
              "      \"finished_at\": null,\n",
              "      \"fine_tuned_model\": null,\n",
              "      \"organization_id\": \"org-HSbO0AHQitnU5PUzeD33jzWV\",\n",
              "      \"result_files\": [],\n",
              "      \"status\": \"running\",\n",
              "      \"validation_file\": null,\n",
              "      \"training_file\": \"file-oslcAaIGlmzqflruENJaJDbl\",\n",
              "      \"hyperparameters\": {\n",
              "        \"n_epochs\": 3\n",
              "      },\n",
              "      \"trained_tokens\": null,\n",
              "      \"error\": null\n",
              "    }\n",
              "  ],\n",
              "  \"has_more\": false\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "job_id = \"ftjob-lrbo5SsbJkPOTZBkCbOkqkbW\""
      ],
      "metadata": {
        "id": "64SpI-oT3_E-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve the state of a fine-tune\n",
        "openai.FineTuningJob.retrieve(job_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYC_pfj4Hh6Q",
        "outputId": "2a5d6464-a3e5-4ce3-edae-445836eb19c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<FineTuningJob fine_tuning.job id=ftjob-lrbo5SsbJkPOTZBkCbOkqkbW at 0x7eedae743bf0> JSON: {\n",
              "  \"object\": \"fine_tuning.job\",\n",
              "  \"id\": \"ftjob-lrbo5SsbJkPOTZBkCbOkqkbW\",\n",
              "  \"model\": \"gpt-3.5-turbo-0613\",\n",
              "  \"created_at\": 1698426471,\n",
              "  \"finished_at\": 1698428014,\n",
              "  \"fine_tuned_model\": \"ft:gpt-3.5-turbo-0613:personal::8EL0BRBX\",\n",
              "  \"organization_id\": \"org-HSbO0AHQitnU5PUzeD33jzWV\",\n",
              "  \"result_files\": [\n",
              "    \"file-wpojZqKIn48ii6tCoXyIKGnU\"\n",
              "  ],\n",
              "  \"status\": \"succeeded\",\n",
              "  \"validation_file\": null,\n",
              "  \"training_file\": \"file-oslcAaIGlmzqflruENJaJDbl\",\n",
              "  \"hyperparameters\": {\n",
              "    \"n_epochs\": 3\n",
              "  },\n",
              "  \"trained_tokens\": 64278,\n",
              "  \"error\": null\n",
              "}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Use a fine-tuned model"
      ],
      "metadata": {
        "id": "kTyE9pEp1JFk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8EL0BRBX\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are CCSIT infobot which provide facts about ccsit\"},\n",
        "    {\"role\": \"user\", \"content\": \"tell me about Dr. Yasser Abdullah Alahmadi?\"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zy_y9u0m1LCl",
        "outputId": "48d28847-7733-44bd-f052-79999f631955"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"Dr. Yasser Abdullah Alahmadi is an assistant Professor in the College of Computer Science and Information Technology. He is associated with the Department of Computer Engineering. You can reach him via phone at 00966-13-333-2012 or email at yalahmadi@iau.edu.sa.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.ChatCompletion.create(\n",
        "  model=\"ft:gpt-3.5-turbo-0613:personal::8EL0BRBX\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are CCSIT infobot which provide facts about ccsit \"},\n",
        "    {\"role\": \"user\", \"content\": \"what aramco chair offer? \"}\n",
        "  ]\n",
        ")\n",
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v3PUd5hL43Ky",
        "outputId": "05cb6b2d-aff0-473f-b79a-5cf66b6f9dd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"role\": \"assistant\",\n",
            "  \"content\": \"The Aramco Chair in Computer Science offers scholarships and research grants for faculty members, as well as funding for research projects, scientific workshops, and conferences. It also supports various academic activities and initiatives in the field of computer science.\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analyzing your fine-tuned model"
      ],
      "metadata": {
        "id": "YcCJBuxE5NHR"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ggsUId748DN7"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}